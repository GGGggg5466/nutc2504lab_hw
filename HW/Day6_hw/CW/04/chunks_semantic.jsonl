{"id": "data_01.txt::0", "source": "data_01.txt", "chunk_id": 0, "start_token": 0, "end_token": 158, "text": "今天是2月2日星期一，台中市迎來了一個涼爽而舒適的清晨。\n凌晨時分，氣溫約在攝氏16度左右，空氣中帶著冬季特有的清新感。\n隨著太陽逐漸升起，天空呈現出淡藍色的基調，偶有幾朵白雲悠閒地飄過，預計白天最高溫將攀升至23度左右。", "source_path": "data/data_01.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_01.txt::1", "source": "data_01.txt", "chunk_id": 1, "start_token": 158, "end_token": 263, "text": "早晨的微風從東北方向吹來，風速溫和，約為每秒3到4公尺，帶來了些許涼意。\n相對濕度維持在65%至75%之間，雖然不至於感到潮濕，但空氣中仍保有一定的水氣。", "source_path": "data/data_01.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_01.txt::2", "source": "data_01.txt", "chunk_id": 2, "start_token": 263, "end_token": 370, "text": "能見度良好，適合外出活動。\n隨著午後時光到來，陽光逐漸增強，市區的氣溫將達到全日最高點。\n雖然還是冬末春初的季節，但台中的陽光已經開始展現出春天的溫暖。", "source_path": "data/data_01.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_01.txt::3", "source": "data_01.txt", "chunk_id": 3, "start_token": 370, "end_token": 458, "text": "建議外出時穿著輕薄的長袖衣物，並隨身攜帶一件薄外套，以應對早晚溫差。\n傍晚時分，氣溫將緩慢下降至19度左右。", "source_path": "data/data_01.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_01.txt::4", "source": "data_01.txt", "chunk_id": 4, "start_token": 458, "end_token": 563, "text": "今日整體而言是個適合戶外活動的好天氣，無論是散步、騎車或是進行戶外運動都相當適宜。\n夜間氣溫將降回17度，天空依然保持晴朗，是個寧靜舒適的二月之夜。", "source_path": "data/data_01.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_02.txt::0", "source": "data_02.txt", "chunk_id": 0, "start_token": 0, "end_token": 80, "text": "台灣位於亞熱帶地區，屬於季風氣候範圍，其中北部為副熱帶季風氣候區，南部則接近熱帶季風氣候區。", "source_path": "data/data_02.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_02.txt::1", "source": "data_02.txt", "chunk_id": 1, "start_token": 80, "end_token": 218, "text": "由於台灣是海島型態，受到暖濕氣流和洋流的影響，因此具有明顯的海洋性氣候特徵。\n## 溫度特徵\n台灣全年溫暖，年平均溫度約為22至24度。\n溫度分布呈現由北向南遞增的趨勢，南部年均溫約為24度，北部約為22度。", "source_path": "data/data_02.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_02.txt::2", "source": "data_02.txt", "chunk_id": 2, "start_token": 218, "end_token": 299, "text": "最熱月為七月，均溫約在27至28度左右，南北差異不大。\n最冷月份為一月與二月，北部約為15度，南部約為19度，南北溫差較大。", "source_path": "data/data_02.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_02.txt::3", "source": "data_02.txt", "chunk_id": 3, "start_token": 299, "end_token": 411, "text": "整體而言，台灣年溫差約在10度上下，較同緯度的大陸型氣候溫和許多。\n## 季風與降雨\n台灣的氣候變化受季風主導。\n夏季吹西南季風，為西南部帶來豐沛的地形雨；", "source_path": "data/data_02.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_02.txt::4", "source": "data_02.txt", "chunk_id": 4, "start_token": 411, "end_token": 586, "text": "冬季則吹東北季風，使得東北部迎風面多雨，形成「竹風蘭雨」及基隆「雨港」的特色。\n降雨分布呈現明顯的區域差異：北部全年有雨，年雨量可達2,000至2,500公厘；\n南部則呈現夏雨冬乾的特徵，5月至9月為雨季，10月至翌年4月為乾季，年雨量約1,500至2,000公厘。", "source_path": "data/data_02.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_02.txt::5", "source": "data_02.txt", "chunk_id": 5, "start_token": 586, "end_token": 698, "text": "此外，春季梅雨與夏秋季颱風也是台灣重要的降雨來源。\n由於地勢高聳，台灣山區廣布溫帶植物，高山地區冬季甚至會降雪，展現出從平地到高山的多樣氣候型態。", "source_path": "data/data_02.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_03.txt::0", "source": "data_03.txt", "chunk_id": 0, "start_token": 0, "end_token": 220, "text": "日本最近天氣很冷，甚至常常下大雪。\n日旅達人林氏璧在「日本自助旅遊中毒者」臉書粉專表示，日本第二波流感流行來了。\n氣象粉專「台灣颱風論壇｜天氣特急」日前表示，根據最新模式資料顯示，2月7日至9日之間，預估將有一波相當強的冷空氣襲捲東亞、東北亞，日本、韓國一帶可能出現強風、降雪甚至暴風雪，天氣條件偏向惡劣。", "source_path": "data/data_03.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_03.txt::1", "source": "data_03.txt", "chunk_id": 1, "start_token": 220, "end_token": 352, "text": "林氏璧指出，日本流感患者人數自去年11月達到高峰後，到1月初探底，但日本最近很冷， 果然流行曲線又整體高了起來。\n目前台日兩邊流感都開始了這個秋冬的第二波流感流行，不只是之前的A型H3N2，也混著B型流感。", "source_path": "data/data_03.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_03.txt::2", "source": "data_03.txt", "chunk_id": 2, "start_token": 352, "end_token": 448, "text": "林氏璧說，根據國立健康危機管理研究機構的報告，截至1月25日的一周內，全日本3000多家醫療機構報告的流感患者人數為6萬3326人。", "source_path": "data/data_03.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_03.txt::3", "source": "data_03.txt", "chunk_id": 3, "start_token": 448, "end_token": 528, "text": "每家醫療機構平均通報患者數從最高點的51.12人，降為最低點10.35後，接下來10.54、11.33，本周則是16.64，連續3周增加。", "source_path": "data/data_03.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_03.txt::4", "source": "data_03.txt", "chunk_id": 4, "start_token": 528, "end_token": 630, "text": "林氏璧指出，九州還是在流行，原本躺平的關東，特別是東京周邊縣份又出現在榜單上了。\n全日本47個都道府縣中，有38個都道府縣超過10人，還是有一定的流行。", "source_path": "data/data_03.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_03.txt::5", "source": "data_03.txt", "chunk_id": 5, "start_token": 630, "end_token": 724, "text": "有42個的患者數比前一周增加，僅有5個比前周減少。\n東京目前比較流行的區域包括八王子市，町田市，中野區，豐島區，北區，荒川區，江東區。", "source_path": "data/data_03.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_03.txt::6", "source": "data_03.txt", "chunk_id": 6, "start_token": 724, "end_token": 804, "text": "他表示，至於最近5周間鑑定的病毒型別，以A型H3為主占74%，B型26％。\nB型流感占比明顯增加。\n所以這波是混著B流而來的第二波。", "source_path": "data/data_03.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_04.txt::0", "source": "data_04.txt", "chunk_id": 0, "start_token": 0, "end_token": 137, "text": "去年11月，Google Cloud宣布代號為Ironwood的第7代TPU正式推出，受到全世界熱烈關注之餘，他們也預告同樣是自行研發的Arm架構處理器Axion，將用於建置新的雲端執行個體服務，當時預告幾週之後，將開放預覽版本供大家測試。", "source_path": "data/data_04.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_04.txt::1", "source": "data_04.txt", "chunk_id": 1, "start_token": 137, "end_token": 359, "text": "首先是2024年上市的C4A，將增設裸機組態，稱為C4A metal，是該公司第一款導入Arm架構的裸機運算服務，能為特殊類型的工作負載提供專屬於單一用戶執行的實體伺服器系統，像是Android系統與應用程式的開發、自動駕駛車輛內部系統執行、測試系統規模的擴展、複雜模擬作業的執行，或是須符合嚴格軟體授權要求的狀況。", "source_path": "data/data_04.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_04.txt::2", "source": "data_04.txt", "chunk_id": 2, "start_token": 359, "end_token": 461, "text": "另一個突破是增設雲端虛擬機器系列，稱為N4A，是Google Cloud旗下第二批採用Axion處理器的一般用途虛擬機器，也是目前最具成本效益的N系列虛擬機器服務。", "source_path": "data/data_04.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_04.txt::3", "source": "data_04.txt", "chunk_id": 3, "start_token": 461, "end_token": 542, "text": "相較於採用當前主流世代x86架構CPU的虛擬機器，N4A可提供兩倍的性價比（price-performance），以及每瓦效能領先幅度達到80％的能源使用效率。", "source_path": "data/data_04.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_04.txt::4", "source": "data_04.txt", "chunk_id": 4, "start_token": 542, "end_token": 683, "text": "N4A適合的工作負載類型相當多元，包括：微服務、容器化應用系統、開放原始碼資料庫系統、批次處理、資料分析、軟體開發環境的設置、實驗測試、資料的準備、網站服務的提供，協助用戶實現各種AI應用。", "source_path": "data/data_04.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_04.txt::5", "source": "data_04.txt", "chunk_id": 5, "start_token": 683, "end_token": 803, "text": "Google Cloud也公開N4A執行多種應用系統的性價比提升幅度，像是處理偏重運算能力要求的工作，N4A能夠比x86虛擬機器高出5％；\n用於一般用途的資料庫系統（MySQL的每秒交易量），N4A的領先幅度為20％；", "source_path": "data/data_04.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_04.txt::6", "source": "data_04.txt", "chunk_id": 6, "start_token": 803, "end_token": 908, "text": "承載Java應用系統（SPECjbb2015的每秒運作量），N4A的成本效益高出85％；\n若是執行橫向擴展規模的網站伺服器系統（Google內部的Nginx反向代理測試），N4A的領先比例為90％；", "source_path": "data/data_04.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_04.txt::7", "source": "data_04.txt", "chunk_id": 7, "start_token": 908, "end_token": 1052, "text": "若只看CPU運算效能（SPECrate2017整數運算），N4A的性價比可達到205％。\n關於硬體配備，Google Cloud當時透露N4A搭配最新一代的Google Axion處理器，內建Arm Neoverse N3平臺的運算核心，整合Google發展的動態資源管理技術，以及Titanium網路與儲存工作卸載技術。", "source_path": "data/data_04.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_04.txt::8", "source": "data_04.txt", "chunk_id": 8, "start_token": 1052, "end_token": 1219, "text": "到了今年1月底，Google Cloud宣布N4A正式上線，相較於去年底預覽版僅供應4個區域：us-central1（愛荷華州）、us-east4（北維吉尼亞州）、 europe-west3（法蘭克福）、europe-west4（荷蘭），現在擴及us-east1（南卡羅萊納州）、us-west1（奧勒岡州）、asia-southeast1（新加坡）、 europe-west1（比利時）、europe-west2（倫敦）。", "source_path": "data/data_04.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_04.txt::9", "source": "data_04.txt", "chunk_id": 9, "start_token": 1219, "end_token": 1325, "text": "而關於Google Cloud企業級容器平臺GKE的支援上，用戶在GKE叢集的Autopilot（全代管）或標準運作模式當中，均可選用N4A系列虛擬機器，以前者而言，GKE叢集需使用1.34.1-gke.3403001的版本。", "source_path": "data/data_04.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_05.txt::0", "source": "data_05.txt", "chunk_id": 0, "start_token": 0, "end_token": 172, "text": "Google更新裝置端推論框架LiteRT，宣布在Google I/O 2025預告的進階硬體加速能力，已正式納入LiteRT產品堆疊並對開發者開放。\n這次更新把GPU與NPU的加速流程補齊，其中GPU支援從I/O 2025當時先在Android導入的路徑，擴大到Android、iOS、macOS、Windows、Linux與Web，讓裝置端AI推論在行動端、桌面與網頁之間更一致。", "source_path": "data/data_05.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_05.txt::1", "source": "data_05.txt", "chunk_id": 1, "start_token": 172, "end_token": 276, "text": "LiteRT技術堆疊從TensorFlow Lite的基礎往前推進，過去TensorFlow Lite主要服務傳統機器學習推論，而LiteRT的定位則是接手新一代裝置端AI需求，包含更廣泛的硬體加速與跨平臺部署。", "source_path": "data/data_05.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_05.txt::2", "source": "data_05.txt", "chunk_id": 2, "start_token": 276, "end_token": 417, "text": "LiteRT的GPU加速支援範圍涵蓋Android、iOS、macOS、Windows、Linux與Web，並透過ML Drift這套下一代GPU引擎，串接OpenCL、OpenGL、Metal與WebGPU等後端。\n在Android裝置上，LiteRT會在可用時優先採用OpenCL以取得較高效能，必要時退回OpenGL，其他平臺則改以各自的GPU後端，例如macOS使用Metal，Windows與Linux使用WebGPU。", "source_path": "data/data_05.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_05.txt::3", "source": "data_05.txt", "chunk_id": 3, "start_token": 417, "end_token": 575, "text": "Google表示，在多種模型的平均情境下，LiteRT的GPU效能平均約比既有的TensorFlow Lite GPU委派快1.4倍。\nLiteRT的效能改善，來自推論從輸入到輸出的整體等待時間縮短，Google讓裝置端推論更少依賴CPU執行額外的等待與資料處理，並降低資料在不同硬體之間搬移時造成的延遲。", "source_path": "data/data_05.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_05.txt::4", "source": "data_05.txt", "chunk_id": 4, "start_token": 575, "end_token": 693, "text": "Google點出目前NPU的挑戰不是單一硬體效能，而是生態系碎片化。\n面對不同晶片平臺與各家供應商工具鏈差異，開發者通常得用多套方式，才能把同一個模型部署到不同裝置，導致維運成本上升。", "source_path": "data/data_05.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_05.txt::5", "source": "data_05.txt", "chunk_id": 5, "start_token": 693, "end_token": 780, "text": "LiteRT的訴求是把差異整合進同一套機制，讓開發者以較一致的方法啟用NPU加速，並在裝置不支援或條件不足時，仍能自動改用GPU或CPU維持可用性。", "source_path": "data/data_05.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_05.txt::6", "source": "data_05.txt", "chunk_id": 6, "start_token": 780, "end_token": 905, "text": "在NPU部署流程上，Google把工作流簡化為三個步驟，包含可選的AOT預先編譯、在Android上可搭配Google Play for On-device AI將模型與執行階段交付到相容裝置，以及由LiteRT執行環境負責啟用NPU委派並在條件不足時回退到GPU或CPU。", "source_path": "data/data_05.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
{"id": "data_05.txt::7", "source": "data_05.txt", "chunk_id": 7, "start_token": 905, "end_token": 1095, "text": "同時，LiteRT提供AOT與裝置端JIT兩種編譯策略，讓開發者在啟動速度與首次執行成本之間做取捨。\nLiteRT維持以.tflite格式作為跨平臺部署的共同基礎，開發者可利用PyTorch、TensorFlow與JAX等常見訓練框架轉換模型，讓不同來源的模型都能接上同一套裝置端推論與硬體加速能力，降低因訓練框架不同而造成的部署分歧。", "source_path": "data/data_05.txt", "tokenizer": "tiktoken(cl100k_base)", "method": "semantic", "max_tokens": 256, "min_tokens": 80, "sim_threshold": 0.12}
