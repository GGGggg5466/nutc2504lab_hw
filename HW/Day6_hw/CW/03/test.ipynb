{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c08b5a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "from typing import List, Dict\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from qdrant_client import QdrantClient, models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e6e554",
   "metadata": {},
   "source": [
    "## 1) 連線資訊（Embed API / LLM API / Qdrant）\n",
    "\n",
    "- Qdrant：`http://localhost:6333`\n",
    "- Embed API：你提供的 `/embed`（回傳 4096 維 embeddings）\n",
    "- LLM（Query Rewrite）：使用你測通的 `/v1/chat/completions` 與 model id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7178f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/models/gpt-oss-120b'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== Qdrant =====\n",
    "QDRANT_URL = \"http://localhost:6333\"\n",
    "COLLECTION_NAME = \"cw03_docs\"\n",
    "VECTOR_SIZE = 4096\n",
    "\n",
    "# ===== Embed API =====\n",
    "EMBED_URL = \"https://ws-04.wade0426.me/embed\"\n",
    "EMBED_TASK_DESC = \"檢索技術文件\"   # 依你課堂設定\n",
    "EMBED_NORMALIZE = True\n",
    "\n",
    "# ===== LLM for Query Rewrite =====\n",
    "LLM_BASE = \"https://ws-03.wade0426.me\"\n",
    "LLM_API = f\"{LLM_BASE}/v1/chat/completions\"\n",
    "\n",
    "# 建議你用「動態抓 model id」避免打錯\n",
    "def get_first_model_id() -> str:\n",
    "    r = requests.get(f\"{LLM_BASE}/v1/models\", timeout=20)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()[\"data\"]\n",
    "    return data[0][\"id\"]\n",
    "\n",
    "MODEL_ID = get_first_model_id()\n",
    "MODEL_ID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e15a35",
   "metadata": {},
   "source": [
    "## 2) 讀取 5 個 txt 並切塊（Chunking）\n",
    "\n",
    "這裡先用「固定字數切塊」的方式，優點是穩定、容易 debug。  \n",
    "如果你想改成「用空行分段」，我們之後再換 chunk function。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a2f7366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " ['data_01.txt', 'data_02.txt', 'data_03.txt', 'data_04.txt', 'data_05.txt'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"data\"\n",
    "TXT_GLOB = os.path.join(DATA_DIR, \"data_*.txt\")\n",
    "\n",
    "def read_all_txt_files(pattern: str) -> List[str]:\n",
    "    paths = sorted(glob.glob(pattern))\n",
    "    texts = []\n",
    "    for p in paths:\n",
    "        with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "            texts.append(f.read())\n",
    "    return texts, paths\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = 500, overlap: int = 80) -> List[str]:\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return []\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        chunk = text[start:end].strip()\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "        if end == len(text):\n",
    "            break\n",
    "        start = max(0, end - overlap)\n",
    "    return chunks\n",
    "\n",
    "raw_texts, paths = read_all_txt_files(TXT_GLOB)\n",
    "len(paths), [os.path.basename(p) for p in paths]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaf909b",
   "metadata": {},
   "source": [
    "## 3) 產生 documents（chunk 清單）與 metadata\n",
    "\n",
    "我們會把每個 chunk 存進 Qdrant payload：\n",
    "- source_file：來源檔名\n",
    "- chunk_id：同一檔案內的 chunk 編號\n",
    "- text：chunk 內容（用於回傳給 LLM 或檢查）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd222f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " {'source_file': 'data_01.txt', 'chunk_id': 0},\n",
       " '今天是2月2日星期一，台中市迎來了一個涼爽而舒適的清晨。凌晨時分，氣溫約在攝氏16度左右，空氣中帶著')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = []\n",
    "metas = []\n",
    "\n",
    "for p, text in zip(paths, raw_texts):\n",
    "    chunks = chunk_text(text, chunk_size=500, overlap=80)\n",
    "    fname = os.path.basename(p)\n",
    "    for i, ch in enumerate(chunks):\n",
    "        documents.append(ch)\n",
    "        metas.append({\"source_file\": fname, \"chunk_id\": i})\n",
    "\n",
    "len(documents), metas[0], documents[0][:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce17ed1f",
   "metadata": {},
   "source": [
    "## 4) 呼叫 Embed API 產生 doc_embeddings（4096 維）\n",
    "\n",
    "doc_embeddings 會是一個 list，長度要等於 documents 數量。  \n",
    "每個元素是一個 4096 維的 float list。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40856b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/10] embedded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 4096)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_embeddings(texts: List[str]) -> List[List[float]]:\n",
    "    r = requests.post(\n",
    "        EMBED_URL,\n",
    "        json={\n",
    "            \"texts\": texts,\n",
    "            \"task_description\": EMBED_TASK_DESC,\n",
    "            \"normalize\": EMBED_NORMALIZE\n",
    "        },\n",
    "        timeout=120\n",
    "    )\n",
    "    r.raise_for_status()\n",
    "    return r.json()[\"embeddings\"]\n",
    "\n",
    "def batch_embed(all_texts: List[str], batch_size: int = 32) -> List[List[float]]:\n",
    "    out = []\n",
    "    for i in range(0, len(all_texts), batch_size):\n",
    "        batch = all_texts[i:i+batch_size]\n",
    "        emb = get_embeddings(batch)\n",
    "        out.extend(emb)\n",
    "        print(f\"[{i+len(batch)}/{len(all_texts)}] embedded\")\n",
    "    return out\n",
    "\n",
    "doc_embeddings = batch_embed(documents, batch_size=32)\n",
    "len(doc_embeddings), len(doc_embeddings[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255138dd",
   "metadata": {},
   "source": [
    "## 5) 建立 Qdrant collection（Dense-only, 4096 dim）\n",
    "\n",
    "CW03 不做 hybrid，所以只建立單一向量欄位。  \n",
    "distance 我們用 COSINE（常見 embedding 檢索）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cf54826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ collection recreated: cw03_docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3443/3950388618.py:3: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    }
   ],
   "source": [
    "client = QdrantClient(url=QDRANT_URL)\n",
    "\n",
    "client.recreate_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=VECTOR_SIZE,\n",
    "        distance=models.Distance.COSINE,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"✅ collection recreated:\", COLLECTION_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee367028",
   "metadata": {},
   "source": [
    "## 6) Upsert points 到 Qdrant\n",
    "\n",
    "這裡用 `PointStruct` 避免你剛剛遇到的：\n",
    "`dict object has no attribute 'id'`  \n",
    "（新版 client 期待物件，不一定吃 dict）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68313f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upsert ok: 10\n"
     ]
    }
   ],
   "source": [
    "points = []\n",
    "for idx, (doc, emb, meta) in enumerate(zip(documents, doc_embeddings, metas)):\n",
    "    points.append(\n",
    "        models.PointStruct(\n",
    "            id=uuid.uuid4().hex,\n",
    "            vector=emb,\n",
    "            payload={\n",
    "                \"text\": doc,\n",
    "                **meta\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "client.upsert(collection_name=COLLECTION_NAME, points=points)\n",
    "print(\"✅ upsert ok:\", len(points))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94985510",
   "metadata": {},
   "source": [
    "## 7) Query Rewrite（讀 Prompt_ReWrite.txt）\n",
    "\n",
    "我們會把原始問題丟給 LLM，讓它輸出「一行改寫後的搜尋語句」。  \n",
    "注意：我們會做 `splitlines()[0]`，確保只取第一行避免模型碎念。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1f78155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Google Cloud N4A 虛擬機器 使用 哪款 處理器'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT_PATH = \"Prompt_ReWrite.txt\"\n",
    "\n",
    "with open(PROMPT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    prompt_system = f.read().strip()\n",
    "\n",
    "def rewrite_query(original_question: str) -> str:\n",
    "    resp = requests.post(\n",
    "        LLM_API,\n",
    "        json={\n",
    "            \"model\": MODEL_ID,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": prompt_system},\n",
    "                {\"role\": \"user\", \"content\": original_question},\n",
    "            ],\n",
    "            \"temperature\": 0.2,\n",
    "        },\n",
    "        timeout=60\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    text = resp.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    return text.splitlines()[0].strip()\n",
    "\n",
    "# quick test\n",
    "rewrite_query(\"Google Cloud 的 N4A 虛擬機器採用哪一款處理器？\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ed48c3",
   "metadata": {},
   "source": [
    "## 8) Dense Retrieval：用改寫後 query 做向量檢索\n",
    "\n",
    "流程：\n",
    "1. rewrite 出新 query\n",
    "2. 對新 query 做 embedding\n",
    "3. 用 Qdrant search 取 top_k chunks\n",
    "4. 把 chunks 組成 context（後面可接 LLM 回答，但 CW03 你目前只要到 retrieval 也行）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63a6080e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始: Google Cloud 的 N4A 虛擬機器採用哪一款處理器？\n",
      "改寫: Google Cloud N4A 虛擬機器 使用 的 處理器 型號是什么\n",
      "Top1 keys: dict_keys(['text', 'source_file', 'chunk_id'])\n",
      "Top1 source: data_04.txt chunk: 2\n",
      "on處理器，內建Arm Neoverse N3平臺的運算核心，整合Google發展的動態資源管理技術，以及Titanium網路與儲存工作卸載技術。\n",
      "\n",
      "到了今年1月底，Google Cloud宣布N4A正式上線，相較於去年底預覽版僅供應4個區域：us-central1（愛荷華州）、us-east4（北維吉尼亞州）、 europe-west3（法蘭克福）、europe-west4（荷蘭），現在擴及us\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import models\n",
    "\n",
    "def dense_search(query: str, top_k: int = 5):\n",
    "    # 取得 query embedding (4096-d)\n",
    "    q_vec = get_embeddings([query])[0]   # <-- 你前面已經有 get_embeddings()\n",
    "\n",
    "    # ✅ 版本相容寫法：優先 search_points，否則 query_points\n",
    "    if hasattr(client, \"search_points\"):\n",
    "        res = client.search_points(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            vector=q_vec,\n",
    "            limit=top_k,\n",
    "            with_payload=True,\n",
    "        )\n",
    "        # search_points 直接回傳 list[ScoredPoint]\n",
    "        return res\n",
    "    else:\n",
    "        res = client.query_points(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            query=q_vec,\n",
    "            limit=top_k,\n",
    "            with_payload=True,\n",
    "        )\n",
    "        # query_points 回傳 QueryResponse，結果在 .points\n",
    "        return res.points\n",
    "\n",
    "q0 = \"Google Cloud 的 N4A 虛擬機器採用哪一款處理器？\"\n",
    "rq0 = rewrite_query(q0)\n",
    "\n",
    "hits = dense_search(rq0, top_k=5)\n",
    "\n",
    "print(\"原始:\", q0)\n",
    "print(\"改寫:\", rq0)\n",
    "print(\"Top1 keys:\", hits[0].payload.keys())\n",
    "print(\"Top1 source:\", hits[0].payload.get(\"source_file\"), \"chunk:\", hits[0].payload.get(\"chunk_id\"))\n",
    "print(hits[0].payload.get(\"text\", \"\")[:200])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e434f34",
   "metadata": {},
   "source": [
    "## 9) 讀取 Re_Write_questions.csv 並批次跑「改寫 + 檢索」\n",
    "\n",
    "你作業如果要求交付結果，可以把：\n",
    "- 原始問題\n",
    "- 改寫後問題\n",
    "- top_k 取到的 chunk（或只存 top1）\n",
    "輸出成新的 csv / json 方便檢查。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1247c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>questions_id</th>\n",
       "      <th>questions</th>\n",
       "      <th>answer</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Google Cloud 的 N4A 虛擬機器有什麼特色？</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>它跟上一代的 C4A 有什麼不同？</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>那目前可以在哪些地區使用這個服務？</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_id  questions_id                      questions  answer  \\\n",
       "0                1             1  Google Cloud 的 N4A 虛擬機器有什麼特色？     NaN   \n",
       "1                1             2              它跟上一代的 C4A 有什麼不同？     NaN   \n",
       "2                1             3              那目前可以在哪些地區使用這個服務？     NaN   \n",
       "\n",
       "   source  \n",
       "0     NaN  \n",
       "1     NaN  \n",
       "2     NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rwq_df = pd.read_csv(\"Re_Write_questions.csv\")\n",
    "rwq_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aa0215",
   "metadata": {},
   "source": [
    "## 10) (Step 4) 用 Retrieval 結果 + LLM 生成答案\n",
    "\n",
    "流程：\n",
    "1. 對每個問題做 rewrite\n",
    "2. 用 rewrite 後的 query 去 Qdrant 取 top_k chunks\n",
    "3. 把 chunks 組成 context 丟給 LLM\n",
    "4. 回傳 answer，並把使用到的來源（source_file / chunk_id）記錄下來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61a5c1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_with_context(question: str, hits, max_ctx_chars: int = 4000) -> dict:\n",
    "    \"\"\"\n",
    "    hits: qdrant 回傳的點列表（top_k）\n",
    "    回傳：{\"answer\": str, \"sources\": list[dict]}\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) 把 top_k chunks 組成 context（含來源）\n",
    "    ctx_lines = []\n",
    "    sources = []\n",
    "    total = 0\n",
    "\n",
    "    for h in hits:\n",
    "        payload = h.payload or {}\n",
    "        text = (payload.get(\"text\") or \"\").strip()\n",
    "        src = payload.get(\"source_file\")\n",
    "        cid = payload.get(\"chunk_id\")\n",
    "\n",
    "        # 記錄來源\n",
    "        sources.append({\"source_file\": src, \"chunk_id\": cid})\n",
    "\n",
    "        line = f\"[{src} | chunk {cid}]\\n{text}\\n\"\n",
    "        if total + len(line) > max_ctx_chars:\n",
    "            break\n",
    "        ctx_lines.append(line)\n",
    "        total += len(line)\n",
    "\n",
    "    context = \"\\n---\\n\".join(ctx_lines).strip()\n",
    "\n",
    "    # 2) 給 LLM 的 system prompt（可依老師風格微調）\n",
    "    prompt_system_answer = (\n",
    "        \"你是一個助教型問答系統。\"\n",
    "        \"只能根據我提供的 context 回答，不要編造。\"\n",
    "        \"若 context 不足以回答，請回答：『資料不足，無法從文件中確認。』\"\n",
    "        \"回答用繁體中文，簡潔但完整。\"\n",
    "    )\n",
    "\n",
    "    # 3) 送出 LLM\n",
    "    user_content = f\"\"\"問題：\n",
    "{question}\n",
    "\n",
    "可用文件片段（context）：\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "    resp = requests.post(\n",
    "        LLM_API,\n",
    "        json={\n",
    "            \"model\": MODEL_ID,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": prompt_system_answer},\n",
    "                {\"role\": \"user\", \"content\": user_content},\n",
    "            ],\n",
    "            \"temperature\": 0.2,\n",
    "        },\n",
    "        timeout=120\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    answer = resp.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "    return {\"answer\": answer, \"sources\": sources}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac3f9f6",
   "metadata": {},
   "source": [
    "## 11) (Step 4) 單題測試：Rewrite → Retrieval → LLM Answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84c9dd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始問題: Google Cloud 的 N4A 虛擬機器採用哪一款處理器？\n",
      "改寫: Google Cloud N4A 虛擬機器 使用 哪款 處理器\n",
      "\n",
      "=== Answer ===\n",
      "Google Cloud 的 N4A 虛擬機器採用的是 **Google 自行研發的 Axion 處理器**（最新一代的 Google Axion，內建 Arm Neoverse N3 平臺的運算核心）。\n",
      "\n",
      "=== Sources ===\n",
      "[{'source_file': 'data_04.txt', 'chunk_id': 2}, {'source_file': 'data_04.txt', 'chunk_id': 0}, {'source_file': 'data_04.txt', 'chunk_id': 1}, {'source_file': 'data_05.txt', 'chunk_id': 2}, {'source_file': 'data_05.txt', 'chunk_id': 1}]\n"
     ]
    }
   ],
   "source": [
    "q0 = \"Google Cloud 的 N4A 虛擬機器採用哪一款處理器？\"\n",
    "\n",
    "rq0 = rewrite_query(q0)                 # 你原本就有\n",
    "hits = dense_search(rq0, top_k=5)       # 你原本就有\n",
    "\n",
    "result = answer_with_context(q0, hits)\n",
    "\n",
    "print(\"原始問題:\", q0)\n",
    "print(\"改寫:\", rq0)\n",
    "print(\"\\n=== Answer ===\")\n",
    "print(result[\"answer\"])\n",
    "print(\"\\n=== Sources ===\")\n",
    "print(result[\"sources\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615bb7e2",
   "metadata": {},
   "source": [
    "## 12) (Step 5) 逐對話批次跑：Rewrite → Retrieval → LLM Answer → 回填 CSV（含對話接續）\n",
    "\n",
    "重點：\n",
    "- `conversation_id` 相同代表同一段對話，要把前面問答當作「對話脈絡」帶入下一題。\n",
    "- 逐列產生：\n",
    "  - `answer`：LLM 的最終回答\n",
    "  - `source`：本次回答用到的來源（source_file / chunk_id），存成 JSON 字串方便交作業檢查\n",
    "- 產出檔案：`questions_answer.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4e126f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3443/2562415613.py:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Google Cloud 的 N4A 系列虛擬機器具備以下特色：\n",
      "\n",
      "1. **硬體與架構**  \n",
      "   - 採用 Google 自研的 **Axion 處理器**，內建 **Arm Neoverse N3** 平台運算核心。  \n",
      "   - 整合 Google 的 **動態資源管理**、**Titanium 網路與儲存卸載** 技術。\n",
      "\n",
      "2. **高性價比與能源效率**  \n",
      "   - 相較於傳統 x86 虛擬機，提供 **約兩倍的 price‑performance**。  \n",
      "   - 每瓦效能領先 **最高可達 80 %**，能源使用效率顯著提升。  \n",
      "   - 在不同工作負載的性價比提升幅度：  \n",
      "     - 計算密集型工作負載 **+5 %** 效能。  \n",
      "     - MySQL 資料庫每秒交易量 **+20 %**。  \n",
      "     - Java 應用（SPECjbb2015）成本效益 **+85 %**。  \n",
      "     - 網站伺服器（Nginx 反向代理）領先 **+90 %**。  \n",
      "     - CPU 整數運算（SPECrate2017）性價比 **達 205 %**。\n",
      "\n",
      "3. **多樣化工作負載支援**  \n",
      "   - 微服務、容器化應用、開源資料庫、批次處理、資料分析、軟體開發環境、實驗測試、資料準備、網站服務等皆適用，亦可用於各種 AI 應用。\n",
      "\n",
      "4. **地域與平台支援**  \n",
      "   - 已在多個區域上線（美國、歐洲、亞洲等），並支援 GKE（Autopilot 與標準模式），使用 GKE 1.34.1‑gke.3403001 以上版本即可選擇 N4A。\n",
      "\n",
      "綜合以上，N4A 以 Arm 架構提供更佳的效能、成本與能源表現，且適用範圍廣泛，是 Google Cloud 目前最具成本效益的 N 系列一般用途虛擬機器。' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  rwq_df.at[idx, \"answer\"] = ans\n",
      "/tmp/ipykernel_3443/2562415613.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[{\"source_file\": \"data_04.txt\", \"chunk_id\": 2}, {\"source_file\": \"data_04.txt\", \"chunk_id\": 1}, {\"source_file\": \"data_04.txt\", \"chunk_id\": 0}, {\"source_file\": \"data_05.txt\", \"chunk_id\": 2}, {\"source_file\": \"data_05.txt\", \"chunk_id\": 1}]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  rwq_df.at[idx, \"source\"] = sources_json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/6] OK  conv=1 qid=1\n",
      "[2/6] OK  conv=1 qid=2\n",
      "[3/6] OK  conv=1 qid=3\n",
      "[4/6] OK  conv=2 qid=1\n",
      "[5/6] OK  conv=2 qid=2\n",
      "[6/6] OK  conv=2 qid=3\n",
      "\n",
      "✅ 產出完成： questions_answer.csv\n",
      "成功筆數: 6\n",
      "失敗筆數: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>questions_id</th>\n",
       "      <th>questions</th>\n",
       "      <th>answer</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Google Cloud 的 N4A 虛擬機器有什麼特色？</td>\n",
       "      <td>Google Cloud 的 N4A 系列虛擬機器具備以下特色：\\n\\n1. **硬體與架構...</td>\n",
       "      <td>[{\"source_file\": \"data_04.txt\", \"chunk_id\": 2}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>它跟上一代的 C4A 有什麼不同？</td>\n",
       "      <td>N4A 與前一代的 C4A 在定位與形態上有以下幾個主要差異：\\n\\n| 項目 | C4A（...</td>\n",
       "      <td>[{\"source_file\": \"data_04.txt\", \"chunk_id\": 2}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>那目前可以在哪些地區使用這個服務？</td>\n",
       "      <td>目前 N4A 服務已在以下 Google Cloud 區域可供使用：\\n\\n- **us‑c...</td>\n",
       "      <td>[{\"source_file\": \"data_04.txt\", \"chunk_id\": 2}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>最近去日本旅遊天氣要注意什麼？</td>\n",
       "      <td>根據目前的資訊，近期前往日本旅遊需要留意以下天氣與健康狀況：\\n\\n1. **寒冷與強風**...</td>\n",
       "      <td>[{\"source_file\": \"data_03.txt\", \"chunk_id\": 0}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>那邊現在有流感疫情嗎？</td>\n",
       "      <td>根據提供的資料，日本目前正處於第二波流感流行。國立健康危機管理研究機構的報告顯示，截至1月2...</td>\n",
       "      <td>[{\"source_file\": \"data_03.txt\", \"chunk_id\": 0}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>東京的情況嚴重嗎？</td>\n",
       "      <td>根據林氏璧的報告，東京的流感情況正呈上升趨勢。全日本 47 個都道府縣中，東京所在的關東地區...</td>\n",
       "      <td>[{\"source_file\": \"data_03.txt\", \"chunk_id\": 0}...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_id  questions_id                      questions  \\\n",
       "0                1             1  Google Cloud 的 N4A 虛擬機器有什麼特色？   \n",
       "1                1             2              它跟上一代的 C4A 有什麼不同？   \n",
       "2                1             3              那目前可以在哪些地區使用這個服務？   \n",
       "3                2             1                最近去日本旅遊天氣要注意什麼？   \n",
       "4                2             2                    那邊現在有流感疫情嗎？   \n",
       "5                2             3                      東京的情況嚴重嗎？   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Google Cloud 的 N4A 系列虛擬機器具備以下特色：\\n\\n1. **硬體與架構...   \n",
       "1  N4A 與前一代的 C4A 在定位與形態上有以下幾個主要差異：\\n\\n| 項目 | C4A（...   \n",
       "2  目前 N4A 服務已在以下 Google Cloud 區域可供使用：\\n\\n- **us‑c...   \n",
       "3  根據目前的資訊，近期前往日本旅遊需要留意以下天氣與健康狀況：\\n\\n1. **寒冷與強風**...   \n",
       "4  根據提供的資料，日本目前正處於第二波流感流行。國立健康危機管理研究機構的報告顯示，截至1月2...   \n",
       "5  根據林氏璧的報告，東京的流感情況正呈上升趨勢。全日本 47 個都道府縣中，東京所在的關東地區...   \n",
       "\n",
       "                                              source  \n",
       "0  [{\"source_file\": \"data_04.txt\", \"chunk_id\": 2}...  \n",
       "1  [{\"source_file\": \"data_04.txt\", \"chunk_id\": 2}...  \n",
       "2  [{\"source_file\": \"data_04.txt\", \"chunk_id\": 2}...  \n",
       "3  [{\"source_file\": \"data_03.txt\", \"chunk_id\": 0}...  \n",
       "4  [{\"source_file\": \"data_03.txt\", \"chunk_id\": 0}...  \n",
       "5  [{\"source_file\": \"data_03.txt\", \"chunk_id\": 0}...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 讀取作業檔\n",
    "rwq_df = pd.read_csv(\"Re_Write_questions.csv\")\n",
    "\n",
    "# 保險：如果 answer/source 欄不存在就補上\n",
    "if \"answer\" not in rwq_df.columns:\n",
    "    rwq_df[\"answer\"] = \"\"\n",
    "if \"source\" not in rwq_df.columns:\n",
    "    rwq_df[\"source\"] = \"\"\n",
    "\n",
    "def format_history_text(history_pairs, max_turns=6) -> str:\n",
    "    \"\"\"\n",
    "    history_pairs: [(q, a), (q, a), ...]\n",
    "    只取最近 max_turns 回合，避免脈絡太長\n",
    "    \"\"\"\n",
    "    use_pairs = history_pairs[-max_turns:]\n",
    "    lines = []\n",
    "    for i, (q, a) in enumerate(use_pairs, 1):\n",
    "        lines.append(f\"Q{i}: {q}\")\n",
    "        lines.append(f\"A{i}: {a}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def rewrite_with_dialogue(original_q: str, history_pairs) -> str:\n",
    "    \"\"\"\n",
    "    把對話脈絡一起給 rewrite（同 conversation_id 接續的核心）\n",
    "    你原本 rewrite_query() 只吃單題，這裡用包裝方式做到「接續」。\n",
    "    \"\"\"\n",
    "    hist = format_history_text(history_pairs, max_turns=6).strip()\n",
    "    if hist:\n",
    "        # 把脈絡 + 現在問題 組成一個輸入，交給 rewrite_query() 生成更合理的改寫\n",
    "        combined = f\"對話脈絡：\\n{hist}\\n\\n現在使用者的問題：\\n{original_q}\"\n",
    "        return rewrite_query(combined)\n",
    "    else:\n",
    "        return rewrite_query(original_q)\n",
    "\n",
    "def run_one_row(q: str, history_pairs):\n",
    "    # 1) rewrite（含對話脈絡）\n",
    "    rq = rewrite_with_dialogue(q, history_pairs)\n",
    "\n",
    "    # 2) retrieval\n",
    "    hits = dense_search(rq, top_k=5)\n",
    "\n",
    "    # 3) answer（用原始問題 q + hits）\n",
    "    result = answer_with_context(q, hits)\n",
    "\n",
    "    # sources 存成 JSON 字串\n",
    "    sources_json = json.dumps(result[\"sources\"], ensure_ascii=False)\n",
    "\n",
    "    return rq, result[\"answer\"], sources_json\n",
    "\n",
    "# ========== 逐對話批次跑 ==========\n",
    "total = len(rwq_df)\n",
    "ok, fail = 0, 0\n",
    "\n",
    "# 依 conversation_id 分組（同一組就是同一段對話）\n",
    "for conv_id, group_idx in rwq_df.groupby(\"conversation_id\").groups.items():\n",
    "    history_pairs = []  # 這裡累積同一段對話的 (question, answer)\n",
    "\n",
    "    # group_idx 是原 df 的 index 列表，要按 questions_id 排序才像“對話順序”\n",
    "    sub = rwq_df.loc[list(group_idx)].sort_values(\"questions_id\")\n",
    "\n",
    "    for idx, row in sub.iterrows():\n",
    "        q = str(row[\"questions\"])\n",
    "\n",
    "        try:\n",
    "            rq, ans, sources_json = run_one_row(q, history_pairs)\n",
    "\n",
    "            rwq_df.at[idx, \"answer\"] = ans\n",
    "            rwq_df.at[idx, \"source\"] = sources_json\n",
    "\n",
    "            # 更新對話脈絡：下一題會用到上一題的 Q/A\n",
    "            history_pairs.append((q, ans))\n",
    "\n",
    "            ok += 1\n",
    "            print(f\"[{ok}/{total}] OK  conv={conv_id} qid={row['questions_id']}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            fail += 1\n",
    "            print(f\"[FAIL] conv={conv_id} qid={row.get('questions_id')} err={type(e).__name__}: {e}\")\n",
    "\n",
    "# 輸出交作業用檔案\n",
    "out_path = \"questions_answer.csv\"\n",
    "rwq_df.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"\\n✅ 產出完成：\", out_path)\n",
    "print(\"成功筆數:\", ok)\n",
    "print(\"失敗筆數:\", fail)\n",
    "\n",
    "rwq_df.sort_values([\"conversation_id\", \"questions_id\"]).head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
